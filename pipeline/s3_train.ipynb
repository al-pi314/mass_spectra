{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Step 3 in the Pipeline - Training ML Prediction Model\n",
    "With this notebook we can train various ML classifiers to tackle multi-lable prediction problem. We are predicting Spec2Vec embeddings from molecular fingerprints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, precision_score, recall_score, jaccard_score, roc_auc_score, hamming_loss, label_ranking_loss, coverage_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import  ClassifierChain\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mass_spectra.similarity_voting import SimilarityVoting\n",
    "from wrappers.nn import NN\n",
    "from wrappers.catboost import CatBoost\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from random import shuffle, seed\n",
    "from math import ceil\n",
    "import os\n",
    "from torch.nn import BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 27082023\n",
    "seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# path to merged fingerprint and embedding data (fingerprint columns should be prefixed with 'fingerprint_' and embedding columns should be prefixed with 'embedding_').\n",
    "MERGED_PATH = './source/embedding/all_positive_all_fingerprints/merged.csv'\n",
    "MODEL_OUTPUT_FOLDER = \"./source/model/all_positive_all_fingerprints/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(MERGED_PATH)\n",
    "assert os.path.isdir(MODEL_OUTPUT_FOLDER)\n",
    "assert MERGED_PATH.endswith('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESTIMATOR = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = CatBoost(num_trees=500, learning_rate =0.001, random_seed=RANDOM_STATE, allow_const_label=True, verbose=False, loss_function='MultiLogloss')\n",
    "MODEL = OneVsRestClassifier(ESTIMATOR, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASS = MODEL.__class__.__name__\n",
    "ESTIMATOR_CLASS = ESTIMATOR.__class__.__name__ if ESTIMATOR is not None else 'Multioutput'\n",
    "MODEL_OUTPUT_FOLDER = f'{MODEL_OUTPUT_FOLDER}{MODEL_CLASS}_{ESTIMATOR_CLASS}'\n",
    "os.makedirs(f'{MODEL_OUTPUT_FOLDER}/models', exist_ok=False)\n",
    "os.makedirs(f'{MODEL_OUTPUT_FOLDER}/unseen_inchi_keys_models', exist_ok=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Definition\n",
    "Creates metrics which can be called with (y_true, y_prob, y_pred) for easier use. It also creates multiple combinations of metrics for different averaging methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_PRED_SCORES = [accuracy_score, log_loss, hamming_loss] # input y predictions and y true\n",
    "Y_PRED_SCORES_WITH_AVERAGING = [f1_score, precision_score, recall_score, jaccard_score] # input y predictions and y true and use one of the following: \"micro\", \"macro\", \"weighted\", \"samples\"\n",
    "Y_PROB_SCORES = [roc_auc_score, label_ranking_loss, coverage_error] # input y probabilities and y true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = []\n",
    "METRIC_NAMES = []\n",
    "for metric in Y_PRED_SCORES:\n",
    "    METRICS.append(lambda y_true, y_prob, y_pred, metric=metric: metric(y_true, y_pred))\n",
    "    METRIC_NAMES.append(metric.__name__)\n",
    "for metric in Y_PRED_SCORES_WITH_AVERAGING:\n",
    "    for average in [\"micro\", \"macro\", \"weighted\", \"samples\"]:\n",
    "        zero_division = 0 if metric.__name__ == \"jaccard_score\" else np.nan\n",
    "        METRICS.append(lambda y_true, y_prob, y_pred, metric=metric, average=average: metric(y_true, y_pred, average=average, zero_division=zero_division))\n",
    "        METRIC_NAMES.append(metric.__name__ + \"__\" + average)\n",
    "for metric in Y_PROB_SCORES:\n",
    "    METRICS.append(lambda y_true, y_prob, y_pred, metric=metric: metric(y_true, y_prob))\n",
    "    METRIC_NAMES.append(metric.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self, metrics, metric_names, repeats=2, folds=5):\n",
    "        self.metrics = metrics\n",
    "        self.metric_names = metric_names\n",
    "        \n",
    "        self.repeats = repeats\n",
    "        self.folds = folds\n",
    "        self.i = 0\n",
    "\n",
    "        self.results = pd.DataFrame(columns=['repeat', 'fold', 'model_training_data_path'] + self.metric_names)\n",
    "    \n",
    "    def evaluate(self, y_true, y_prob, y_pred, model_training_data_path=None):\n",
    "        entry = {\n",
    "            'repeat': self.i // self.folds,\n",
    "            'fold': self.i % self.folds,\n",
    "            'model_training_data_path': model_training_data_path\n",
    "        }\n",
    "        for metric, metric_name in zip(self.metrics, self.metric_names):\n",
    "            try:\n",
    "                entry[metric_name] = metric(y_true, y_prob, y_pred)\n",
    "            except ValueError as e:\n",
    "                print(\"Warning: \", e)\n",
    "                entry[metric_name] = np.nan\n",
    "        \n",
    "        self.results = pd.concat([self.results, pd.DataFrame(entry, index=[0])], ignore_index=True)\n",
    "        self.i += 1\n",
    "    \n",
    "    def store(self, filename):\n",
    "        self.results.to_csv(filename, index=False)\n",
    "\n",
    "    def current(self, metric_name):\n",
    "        return self.results[metric_name].iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3052 entries, 0 to 3051\n",
      "Columns: 605 entries, inchi_key to embedding_299\n",
      "dtypes: float64(300), int64(302), object(3)\n",
      "memory usage: 14.1+ MB\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.read_csv(MERGED_PATH)\n",
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of NaNs: 0'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Number of NaNs: {merged_df.isna().sum().sum()}' # should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3052, 300), (3052, 302))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = merged_df.filter(regex='^embedding_')\n",
    "y = merged_df.filter(regex='^fingerprint_')\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train- K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a7b63286e394ea0a799dae49b7ee4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeats:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda586b7a5da495f86f39911b3a7ffa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.026175160353849754\n",
      "F1 Weighted:  0.7896648213123029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.026880317620413856\n",
      "F1 Weighted:  0.7938960405467362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.028065997086972935\n",
      "F1 Weighted:  0.781986985310107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.029446930962815775\n",
      "F1 Weighted:  0.7722656806742612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.02794301886284499\n",
      "F1 Weighted:  0.7844468723459775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e1b331bbfd42ee83223672d80a0809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.02810112942551758\n",
      "F1 Weighted:  0.7850888587863772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.030332323709172392\n",
      "F1 Weighted:  0.7757286839576808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.02748394843916167\n",
      "F1 Weighted:  0.7768668306226526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.02694477230083883\n",
      "F1 Weighted:  0.7878886629074949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.026739617263915254\n",
      "F1 Weighted:  0.7886796425034566\n"
     ]
    }
   ],
   "source": [
    "REPEATS = 2\n",
    "K = 5\n",
    "metrics = Metrics(METRICS, METRIC_NAMES, REPEATS, K)\n",
    "\n",
    "for i in tqdm(range(REPEATS), desc=\"Repeats\"):\n",
    "    kf = KFold(n_splits=K, shuffle=True, random_state=RANDOM_STATE + i)\n",
    "\n",
    "    for fold, (train_index, test_index) in tqdm(enumerate(kf.split(X, y)), desc=\"Fold\", total=K):\n",
    "        # train\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        MODEL.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = MODEL.predict(X_test)\n",
    "        y_prob = MODEL.predict_proba(X_test)\n",
    "\n",
    "        # store train data\n",
    "        model_training_data_path = f'{MODEL_OUTPUT_FOLDER}/models/{i}_{fold}.pkl'\n",
    "        with open(model_training_data_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"model\": MODEL,\n",
    "                \"X_train\": X_train,\n",
    "                \"y_train\": y_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_test\": y_test,\n",
    "            }, f)\n",
    "\n",
    "        # evaluate\n",
    "        metrics.evaluate(y_test, y_prob, y_pred, model_training_data_path=model_training_data_path)\n",
    "\n",
    "        # display current results\n",
    "        print('Label ranking loss: ', metrics.current('label_ranking_loss'))\n",
    "        print('F1 Weighted: ', metrics.current('f1_score__weighted'))\n",
    "        \n",
    "metrics.store(f'{MODEL_OUTPUT_FOLDER}/metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>f1_score__micro</th>\n",
       "      <th>f1_score__macro</th>\n",
       "      <th>f1_score__weighted</th>\n",
       "      <th>f1_score__samples</th>\n",
       "      <th>precision_score__micro</th>\n",
       "      <th>precision_score__macro</th>\n",
       "      <th>precision_score__weighted</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_score__macro</th>\n",
       "      <th>recall_score__weighted</th>\n",
       "      <th>recall_score__samples</th>\n",
       "      <th>jaccard_score__micro</th>\n",
       "      <th>jaccard_score__macro</th>\n",
       "      <th>jaccard_score__weighted</th>\n",
       "      <th>jaccard_score__samples</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>label_ranking_loss</th>\n",
       "      <th>coverage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.057663</td>\n",
       "      <td>959.839086</td>\n",
       "      <td>0.078278</td>\n",
       "      <td>0.829298</td>\n",
       "      <td>0.476334</td>\n",
       "      <td>0.783651</td>\n",
       "      <td>0.824041</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.760452</td>\n",
       "      <td>0.902192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410009</td>\n",
       "      <td>0.762103</td>\n",
       "      <td>0.773223</td>\n",
       "      <td>0.708403</td>\n",
       "      <td>0.385049</td>\n",
       "      <td>0.700764</td>\n",
       "      <td>0.726037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027811</td>\n",
       "      <td>120.599675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.011842</td>\n",
       "      <td>20.212051</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.004890</td>\n",
       "      <td>0.011774</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.014127</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>0.011182</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>1.183363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.039344</td>\n",
       "      <td>929.760977</td>\n",
       "      <td>0.075053</td>\n",
       "      <td>0.820929</td>\n",
       "      <td>0.452812</td>\n",
       "      <td>0.772266</td>\n",
       "      <td>0.814058</td>\n",
       "      <td>0.904351</td>\n",
       "      <td>0.738910</td>\n",
       "      <td>0.892998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.387391</td>\n",
       "      <td>0.751304</td>\n",
       "      <td>0.761102</td>\n",
       "      <td>0.696250</td>\n",
       "      <td>0.362855</td>\n",
       "      <td>0.687403</td>\n",
       "      <td>0.712257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026175</td>\n",
       "      <td>118.166939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.049590</td>\n",
       "      <td>943.656402</td>\n",
       "      <td>0.077647</td>\n",
       "      <td>0.826160</td>\n",
       "      <td>0.468639</td>\n",
       "      <td>0.778147</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>0.904903</td>\n",
       "      <td>0.748556</td>\n",
       "      <td>0.898420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403359</td>\n",
       "      <td>0.758132</td>\n",
       "      <td>0.770066</td>\n",
       "      <td>0.703812</td>\n",
       "      <td>0.377279</td>\n",
       "      <td>0.696005</td>\n",
       "      <td>0.722166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026896</td>\n",
       "      <td>120.045104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.058920</td>\n",
       "      <td>959.005387</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>0.829837</td>\n",
       "      <td>0.478370</td>\n",
       "      <td>0.784768</td>\n",
       "      <td>0.823454</td>\n",
       "      <td>0.908730</td>\n",
       "      <td>0.760963</td>\n",
       "      <td>0.902851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413239</td>\n",
       "      <td>0.763476</td>\n",
       "      <td>0.774160</td>\n",
       "      <td>0.709164</td>\n",
       "      <td>0.388071</td>\n",
       "      <td>0.701085</td>\n",
       "      <td>0.726125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027713</td>\n",
       "      <td>120.728689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.065083</td>\n",
       "      <td>971.252413</td>\n",
       "      <td>0.078712</td>\n",
       "      <td>0.833050</td>\n",
       "      <td>0.485408</td>\n",
       "      <td>0.788482</td>\n",
       "      <td>0.828309</td>\n",
       "      <td>0.913981</td>\n",
       "      <td>0.772056</td>\n",
       "      <td>0.907411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417883</td>\n",
       "      <td>0.765063</td>\n",
       "      <td>0.776547</td>\n",
       "      <td>0.713870</td>\n",
       "      <td>0.392936</td>\n",
       "      <td>0.706740</td>\n",
       "      <td>0.730787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028092</td>\n",
       "      <td>121.166794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.075410</td>\n",
       "      <td>989.254358</td>\n",
       "      <td>0.081837</td>\n",
       "      <td>0.836302</td>\n",
       "      <td>0.492345</td>\n",
       "      <td>0.793896</td>\n",
       "      <td>0.831907</td>\n",
       "      <td>0.916289</td>\n",
       "      <td>0.777547</td>\n",
       "      <td>0.909168</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424183</td>\n",
       "      <td>0.771812</td>\n",
       "      <td>0.783405</td>\n",
       "      <td>0.718659</td>\n",
       "      <td>0.399820</td>\n",
       "      <td>0.711735</td>\n",
       "      <td>0.737755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>122.618033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_score    log_loss  hamming_loss  f1_score__micro  \\\n",
       "count       10.000000   10.000000     10.000000        10.000000   \n",
       "mean         0.057663  959.839086      0.078278         0.829298   \n",
       "std          0.011842   20.212051      0.002141         0.004890   \n",
       "min          0.039344  929.760977      0.075053         0.820929   \n",
       "25%          0.049590  943.656402      0.077647         0.826160   \n",
       "50%          0.058920  959.005387      0.077832         0.829837   \n",
       "75%          0.065083  971.252413      0.078712         0.833050   \n",
       "max          0.075410  989.254358      0.081837         0.836302   \n",
       "\n",
       "       f1_score__macro  f1_score__weighted  f1_score__samples  \\\n",
       "count        10.000000           10.000000          10.000000   \n",
       "mean          0.476334            0.783651           0.824041   \n",
       "std           0.011774            0.006898           0.005388   \n",
       "min           0.452812            0.772266           0.814058   \n",
       "25%           0.468639            0.778147           0.821719   \n",
       "50%           0.478370            0.784768           0.823454   \n",
       "75%           0.485408            0.788482           0.828309   \n",
       "max           0.492345            0.793896           0.831907   \n",
       "\n",
       "       precision_score__micro  precision_score__macro  \\\n",
       "count               10.000000               10.000000   \n",
       "mean                 0.909509                0.760452   \n",
       "std                  0.004758                0.014127   \n",
       "min                  0.904351                0.738910   \n",
       "25%                  0.904903                0.748556   \n",
       "50%                  0.908730                0.760963   \n",
       "75%                  0.913981                0.772056   \n",
       "max                  0.916289                0.777547   \n",
       "\n",
       "       precision_score__weighted  ...  recall_score__macro  \\\n",
       "count                  10.000000  ...            10.000000   \n",
       "mean                    0.902192  ...             0.410009   \n",
       "std                     0.005733  ...             0.010948   \n",
       "min                     0.892998  ...             0.387391   \n",
       "25%                     0.898420  ...             0.403359   \n",
       "50%                     0.902851  ...             0.413239   \n",
       "75%                     0.907411  ...             0.417883   \n",
       "max                     0.909168  ...             0.424183   \n",
       "\n",
       "       recall_score__weighted  recall_score__samples  jaccard_score__micro  \\\n",
       "count               10.000000              10.000000             10.000000   \n",
       "mean                 0.762103               0.773223              0.708403   \n",
       "std                  0.006019               0.006131              0.007126   \n",
       "min                  0.751304               0.761102              0.696250   \n",
       "25%                  0.758132               0.770066              0.703812   \n",
       "50%                  0.763476               0.774160              0.709164   \n",
       "75%                  0.765063               0.776547              0.713870   \n",
       "max                  0.771812               0.783405              0.718659   \n",
       "\n",
       "       jaccard_score__macro  jaccard_score__weighted  jaccard_score__samples  \\\n",
       "count             10.000000                10.000000               10.000000   \n",
       "mean               0.385049                 0.700764                0.726037   \n",
       "std                0.011182                 0.007755                0.007437   \n",
       "min                0.362855                 0.687403                0.712257   \n",
       "25%                0.377279                 0.696005                0.722166   \n",
       "50%                0.388071                 0.701085                0.726125   \n",
       "75%                0.392936                 0.706740                0.730787   \n",
       "max                0.399820                 0.711735                0.737755   \n",
       "\n",
       "       roc_auc_score  label_ranking_loss  coverage_error  \n",
       "count            0.0           10.000000       10.000000  \n",
       "mean             NaN            0.027811      120.599675  \n",
       "std              NaN            0.001280        1.183363  \n",
       "min              NaN            0.026175      118.166939  \n",
       "25%              NaN            0.026896      120.045104  \n",
       "50%              NaN            0.027713      120.728689  \n",
       "75%              NaN            0.028092      121.166794  \n",
       "max              NaN            0.030332      122.618033  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train With Unseen InChI Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, y, test_inchi_keys=[]):\n",
    "    # get index from merged_df\n",
    "    test_index = merged_df[merged_df['inchi_key'].isin(test_inchi_keys)].index\n",
    "    train_index = merged_df[~merged_df['inchi_key'].isin(test_inchi_keys)].index\n",
    "\n",
    "    # split X and y\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inchi_keys = list(merged_df['inchi_key'].unique())\n",
    "shuffle(all_inchi_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad56f744ced4e82b9093eab9e4d21de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Repeats:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4999ebaccfc64f868c0907f088359a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleks\\anaconda3\\envs\\mass_spectra\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2916: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "Label ranking loss:  0.10723528356252408\n",
      "F1 Weighted:  0.6176084993136549\n"
     ]
    }
   ],
   "source": [
    "hidden_inchi_keys = 10\n",
    "\n",
    "REPEATS = 1\n",
    "K = ceil(len(all_inchi_keys) / hidden_inchi_keys)\n",
    "metrics = Metrics(METRICS, METRIC_NAMES, REPEATS, K)\n",
    "\n",
    "for i in tqdm(range(REPEATS), desc=\"Repeats\"):\n",
    "    # Reshuffle\n",
    "    shuffle(all_inchi_keys)\n",
    "\n",
    "    for end_i in tqdm(range(hidden_inchi_keys, len(all_inchi_keys), hidden_inchi_keys), desc=\"Fold\", total=K):\n",
    "        start_i = end_i - hidden_inchi_keys\n",
    "        if end_i + hidden_inchi_keys > len(all_inchi_keys):\n",
    "            end_i = len(all_inchi_keys)\n",
    "\n",
    "        # train\n",
    "        test_inchi_keys = all_inchi_keys[start_i:end_i]\n",
    "        X_train, X_test, y_train, y_test = split_dataset(X, y, test_inchi_keys)\n",
    "\n",
    "        MODEL.fit(X_train, y_train)\n",
    "\n",
    "        # predict\n",
    "        y_pred = MODEL.predict(X_test)\n",
    "        y_prob = MODEL.predict_proba(X_test)\n",
    "\n",
    "        # store train data\n",
    "        model_training_data_path = f'{MODEL_OUTPUT_FOLDER}/unseen_inchi_keys_models/{start_i}_{end_i}.pkl'\n",
    "        with open(model_training_data_path, \"wb\") as f:\n",
    "            pickle.dump({\n",
    "                \"model\": MODEL,\n",
    "                \"X_train\": X_train,\n",
    "                \"y_train\": y_train,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_test\": y_test,\n",
    "            }, f)\n",
    "\n",
    "        # evaluate\n",
    "        metrics.evaluate(y_test, y_prob, y_pred, model_training_data_path=model_training_data_path)\n",
    "\n",
    "        # display current results\n",
    "        print('Label ranking loss: ', metrics.current('label_ranking_loss'))\n",
    "        print('F1 Weighted: ', metrics.current('f1_score__weighted'))\n",
    "\n",
    "metrics.store(f'{MODEL_OUTPUT_FOLDER}/unseen_inchi_keys_metrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>hamming_loss</th>\n",
       "      <th>f1_score__micro</th>\n",
       "      <th>f1_score__macro</th>\n",
       "      <th>f1_score__weighted</th>\n",
       "      <th>f1_score__samples</th>\n",
       "      <th>precision_score__micro</th>\n",
       "      <th>precision_score__macro</th>\n",
       "      <th>precision_score__weighted</th>\n",
       "      <th>...</th>\n",
       "      <th>recall_score__macro</th>\n",
       "      <th>recall_score__weighted</th>\n",
       "      <th>recall_score__samples</th>\n",
       "      <th>jaccard_score__micro</th>\n",
       "      <th>jaccard_score__macro</th>\n",
       "      <th>jaccard_score__weighted</th>\n",
       "      <th>jaccard_score__samples</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>label_ranking_loss</th>\n",
       "      <th>coverage_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.033491</td>\n",
       "      <td>426.598018</td>\n",
       "      <td>0.074979</td>\n",
       "      <td>0.806446</td>\n",
       "      <td>0.247045</td>\n",
       "      <td>0.755934</td>\n",
       "      <td>0.812042</td>\n",
       "      <td>0.870754</td>\n",
       "      <td>0.304216</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.237586</td>\n",
       "      <td>0.752615</td>\n",
       "      <td>0.771600</td>\n",
       "      <td>0.677001</td>\n",
       "      <td>0.211662</td>\n",
       "      <td>0.697851</td>\n",
       "      <td>0.703763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043242</td>\n",
       "      <td>72.565061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031992</td>\n",
       "      <td>95.871002</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.036732</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.052316</td>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.023611</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.045172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014607</td>\n",
       "      <td>0.057674</td>\n",
       "      <td>0.053199</td>\n",
       "      <td>0.052005</td>\n",
       "      <td>0.013495</td>\n",
       "      <td>0.054956</td>\n",
       "      <td>0.047988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013545</td>\n",
       "      <td>8.173327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>307.650957</td>\n",
       "      <td>0.055945</td>\n",
       "      <td>0.767443</td>\n",
       "      <td>0.224523</td>\n",
       "      <td>0.696720</td>\n",
       "      <td>0.772295</td>\n",
       "      <td>0.842862</td>\n",
       "      <td>0.256751</td>\n",
       "      <td>0.750484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222172</td>\n",
       "      <td>0.684381</td>\n",
       "      <td>0.699187</td>\n",
       "      <td>0.622643</td>\n",
       "      <td>0.193877</td>\n",
       "      <td>0.638442</td>\n",
       "      <td>0.645287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023639</td>\n",
       "      <td>58.740310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.006715</td>\n",
       "      <td>352.639030</td>\n",
       "      <td>0.061487</td>\n",
       "      <td>0.777293</td>\n",
       "      <td>0.241947</td>\n",
       "      <td>0.713578</td>\n",
       "      <td>0.788620</td>\n",
       "      <td>0.851319</td>\n",
       "      <td>0.277501</td>\n",
       "      <td>0.785116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225016</td>\n",
       "      <td>0.712182</td>\n",
       "      <td>0.742136</td>\n",
       "      <td>0.635906</td>\n",
       "      <td>0.202705</td>\n",
       "      <td>0.652776</td>\n",
       "      <td>0.674843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037868</td>\n",
       "      <td>70.576170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.031642</td>\n",
       "      <td>425.280883</td>\n",
       "      <td>0.074950</td>\n",
       "      <td>0.800676</td>\n",
       "      <td>0.248618</td>\n",
       "      <td>0.751705</td>\n",
       "      <td>0.804197</td>\n",
       "      <td>0.871780</td>\n",
       "      <td>0.302393</td>\n",
       "      <td>0.807925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.236053</td>\n",
       "      <td>0.742938</td>\n",
       "      <td>0.763655</td>\n",
       "      <td>0.667607</td>\n",
       "      <td>0.210791</td>\n",
       "      <td>0.690422</td>\n",
       "      <td>0.691723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040428</td>\n",
       "      <td>74.189656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.062933</td>\n",
       "      <td>504.381293</td>\n",
       "      <td>0.087670</td>\n",
       "      <td>0.837234</td>\n",
       "      <td>0.254165</td>\n",
       "      <td>0.798983</td>\n",
       "      <td>0.839447</td>\n",
       "      <td>0.888815</td>\n",
       "      <td>0.334139</td>\n",
       "      <td>0.831494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250278</td>\n",
       "      <td>0.793886</td>\n",
       "      <td>0.814371</td>\n",
       "      <td>0.720572</td>\n",
       "      <td>0.222537</td>\n",
       "      <td>0.744007</td>\n",
       "      <td>0.742109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054106</td>\n",
       "      <td>75.061716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.065891</td>\n",
       "      <td>542.202213</td>\n",
       "      <td>0.095120</td>\n",
       "      <td>0.850960</td>\n",
       "      <td>0.264776</td>\n",
       "      <td>0.819862</td>\n",
       "      <td>0.856939</td>\n",
       "      <td>0.899107</td>\n",
       "      <td>0.349833</td>\n",
       "      <td>0.878601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254885</td>\n",
       "      <td>0.832636</td>\n",
       "      <td>0.836861</td>\n",
       "      <td>0.740583</td>\n",
       "      <td>0.228050</td>\n",
       "      <td>0.765723</td>\n",
       "      <td>0.765722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059277</td>\n",
       "      <td>83.546667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       accuracy_score    log_loss  hamming_loss  f1_score__micro  \\\n",
       "count        6.000000    6.000000      6.000000         6.000000   \n",
       "mean         0.033491  426.598018      0.074979         0.806446   \n",
       "std          0.031992   95.871002      0.016596         0.036732   \n",
       "min          0.000000  307.650957      0.055945         0.767443   \n",
       "25%          0.006715  352.639030      0.061487         0.777293   \n",
       "50%          0.031642  425.280883      0.074950         0.800676   \n",
       "75%          0.062933  504.381293      0.087670         0.837234   \n",
       "max          0.065891  542.202213      0.095120         0.850960   \n",
       "\n",
       "       f1_score__macro  f1_score__weighted  f1_score__samples  \\\n",
       "count         6.000000            6.000000           6.000000   \n",
       "mean          0.247045            0.755934           0.812042   \n",
       "std           0.013885            0.052316           0.034382   \n",
       "min           0.224523            0.696720           0.772295   \n",
       "25%           0.241947            0.713578           0.788620   \n",
       "50%           0.248618            0.751705           0.804197   \n",
       "75%           0.254165            0.798983           0.839447   \n",
       "max           0.264776            0.819862           0.856939   \n",
       "\n",
       "       precision_score__micro  precision_score__macro  \\\n",
       "count                6.000000                6.000000   \n",
       "mean                 0.870754                0.304216   \n",
       "std                  0.023611                0.037554   \n",
       "min                  0.842862                0.256751   \n",
       "25%                  0.851319                0.277501   \n",
       "50%                  0.871780                0.302393   \n",
       "75%                  0.888815                0.334139   \n",
       "max                  0.899107                0.349833   \n",
       "\n",
       "       precision_score__weighted  ...  recall_score__macro  \\\n",
       "count                   6.000000  ...             6.000000   \n",
       "mean                    0.810300  ...             0.237586   \n",
       "std                     0.045172  ...             0.014607   \n",
       "min                     0.750484  ...             0.222172   \n",
       "25%                     0.785116  ...             0.225016   \n",
       "50%                     0.807925  ...             0.236053   \n",
       "75%                     0.831494  ...             0.250278   \n",
       "max                     0.878601  ...             0.254885   \n",
       "\n",
       "       recall_score__weighted  recall_score__samples  jaccard_score__micro  \\\n",
       "count                6.000000               6.000000              6.000000   \n",
       "mean                 0.752615               0.771600              0.677001   \n",
       "std                  0.057674               0.053199              0.052005   \n",
       "min                  0.684381               0.699187              0.622643   \n",
       "25%                  0.712182               0.742136              0.635906   \n",
       "50%                  0.742938               0.763655              0.667607   \n",
       "75%                  0.793886               0.814371              0.720572   \n",
       "max                  0.832636               0.836861              0.740583   \n",
       "\n",
       "       jaccard_score__macro  jaccard_score__weighted  jaccard_score__samples  \\\n",
       "count              6.000000                 6.000000                6.000000   \n",
       "mean               0.211662                 0.697851                0.703763   \n",
       "std                0.013495                 0.054956                0.047988   \n",
       "min                0.193877                 0.638442                0.645287   \n",
       "25%                0.202705                 0.652776                0.674843   \n",
       "50%                0.210791                 0.690422                0.691723   \n",
       "75%                0.222537                 0.744007                0.742109   \n",
       "max                0.228050                 0.765723                0.765722   \n",
       "\n",
       "       roc_auc_score  label_ranking_loss  coverage_error  \n",
       "count            0.0            6.000000        6.000000  \n",
       "mean             NaN            0.043242       72.565061  \n",
       "std              NaN            0.013545        8.173327  \n",
       "min              NaN            0.023639       58.740310  \n",
       "25%              NaN            0.037868       70.576170  \n",
       "50%              NaN            0.040428       74.189656  \n",
       "75%              NaN            0.054106       75.061716  \n",
       "max              NaN            0.059277       83.546667  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.results.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mass_spectra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
