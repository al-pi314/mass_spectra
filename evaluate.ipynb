{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import label_ranking_loss, multilabel_confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINGERPRINTS_PATH = \"./embeddings/tms_maccs_fingerprint.csv\"\n",
    "SPEC2VEC_PATH = \"./embeddings/tms_spec2vec_embeddings.csv\"\n",
    "CLASSIFIER_PATH = \"./models/tms/tms_one_vs_rest_classifier.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(105, 192)\n",
      "Mean true indicators:  36.23809523809524\n",
      "Std true indicators:  17.869464613349937\n",
      "Min true indicators:  21\n",
      "Max true indicators:  192\n",
      "Nan values:  0\n",
      "(3144, 300)\n",
      "Nan values:  0\n",
      "(3082, 492)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3082, 300), (3082, 192))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load and parse data\n",
    "fingerprints = pd.read_csv(FINGERPRINTS_PATH)\n",
    "fingerprints.rename(columns={\"InChIKey\": \"inchikey\", \"Name\": \"name\", \"InChI\": \"inchi\"}, inplace=True)\n",
    "if \"name\" in fingerprints.columns:\n",
    "    fingerprints.drop(columns=[\"name\"], inplace=True)\n",
    "if \"inchi\" in fingerprints.columns:\n",
    "    fingerprints.drop(columns=[\"inchi\"], inplace=True)\n",
    "fingerprints.set_index(\"inchikey\", inplace=True)\n",
    "fingerprints = fingerprints.astype(bool)\n",
    "print(fingerprints.shape)\n",
    "fingerprints.head()\n",
    "# Simple indicator analysis\n",
    "print(\"Mean true indicators: \", fingerprints.sum(axis=1).mean())\n",
    "print(\"Std true indicators: \", fingerprints.sum(axis=1).std())\n",
    "print(\"Min true indicators: \", fingerprints.sum(axis=1).min())\n",
    "print(\"Max true indicators: \", fingerprints.sum(axis=1).max())\n",
    "true_class_weight = 1 - fingerprints.sum(axis=1).mean() / fingerprints.shape[1]\n",
    "false_class_weight = 1 - true_class_weight\n",
    "true_class_weight, false_class_weight\n",
    "# Validate fingerprint\n",
    "print(\"Nan values: \", fingerprints.isna().sum().sum())\n",
    "spec2vec = pd.read_csv(SPEC2VEC_PATH)\n",
    "spec2vec.rename(columns={\"InChI Key\": \"inchikey\", \"Name\": \"name\"}, inplace=True)\n",
    "if \"name\" in spec2vec.columns:\n",
    "    spec2vec = spec2vec.drop(columns=[\"name\"])\n",
    "spec2vec = spec2vec.set_index(\"inchikey\")\n",
    "spec2vec = spec2vec.astype(float)\n",
    "print(spec2vec.shape)\n",
    "spec2vec.head()\n",
    "# Validate embeddings\n",
    "print(\"Nan values: \", spec2vec.isna().sum().sum())\n",
    "# For Both df in index repalce \\xa0 with space and strip (remove leading and trailing spaces)\n",
    "spec2vec.index = spec2vec.index.str.replace(\"\\xa0\", \" \").str.strip()\n",
    "fingerprints.index = fingerprints.index.str.replace(\"\\xa0\", \" \").str.strip()\n",
    "# Missing inchikeys in spec2vec\n",
    "set(fingerprints.index.unique()) - (set(spec2vec.index.unique()))\n",
    "# Missing inchikeys in fingerprints\n",
    "set(spec2vec.index.unique()) - set(fingerprints.index.unique())\n",
    "# Merge the dataframes to obtain X and y matrices (we add suffixes for later extraction)\n",
    "merged = pd.merge(spec2vec.add_suffix(\"_x\"), fingerprints.add_suffix(\"_y\"), left_index=True, right_index=True, how=\"inner\")\n",
    "print(merged.shape)\n",
    "merged.head()\n",
    "# X is data from merged with suffix _x\n",
    "X = merged.filter(regex=\"_x$\").to_numpy()\n",
    "# y is data from merged with suffix _y\n",
    "y = merged.filter(regex=\"_y$\").to_numpy().astype(int)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pickle.load(open(CLASSIFIER_PATH, \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X)\n",
    "mcm = multilabel_confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio 0.18844128542072247, Negative ratio 0.8115587145792775\n"
     ]
    }
   ],
   "source": [
    "# count unique values in y\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(f\"Positive ratio {counts[1] / counts.sum()}, Negative ratio {counts[0] / counts.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column_y = y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive ratio 0.00973393900064893, Negative ratio 0.9902660609993511\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(first_column_y, return_counts=True)\n",
    "print(f\"Positive ratio {counts[1] / counts.sum()}, Negative ratio {counts[0] / counts.sum()}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105412,    776],\n",
       "       [  6097, 479459]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP_sum = mcm[:, 1, 1].sum()\n",
    "FP_sum = mcm[:, 0, 1].sum()\n",
    "TN_sum = mcm[:, 0, 0].sum()\n",
    "FN_sum = mcm[:, 1, 0].sum()\n",
    "\n",
    "cm = np.array([[TP_sum, FP_sum], [FN_sum, TN_sum]])\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mass_spectra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
